{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"isolated_word_recognition.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3QyeBR_Utqam","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","import os\n","list=os.listdir(\"gdrive\")\n","os.chdir(\"gdrive/\"+list[0]+\"/AI_Course\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M8Sex_HnBfxA","colab_type":"code","colab":{}},"source":["os.chdir(\"Digits_pytorch/\")\n","!ls\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQEkIJK-BBCK","colab_type":"code","colab":{}},"source":["import numpy as np\n","import math\n","import os\n","import random\n","import torch.utils.data as data_utils\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn as nn\n","import h5py\n","import torch\n","import torch.optim as optim\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VEywsuKB7Wi","colab_type":"code","colab":{}},"source":["class RawDataset(data_utils.Dataset):\n","    def __init__(self,raw_file,batch_size):\n","        self.raw_file = raw_file \n","        self.batch_size=batch_size\n","        self.h5=h5py.File(self.raw_file,'r')\n","        self.keys=self.h5.keys()\n","    def __len__(self):\n","        \"\"\"Denotes the total number of utterances\n","        \"\"\"\n","        return int(len(self.keys)/self.batch_size)\n","\n","    def __getitem__(self, index):\n","        samples=random.sample(self.keys,self.batch_size)\n","        data=[]\n","        for i in range(0,len(samples)):\n","         data.append(self.h5[samples[i]][:])\n","        return data\n","\n","class ManytooneLstm(nn.Module):\n"," def __init__(self,hidden_cell_dim,inp_dim,out_dim,c0,h0):\n","  super(ManytooneLstm,self).__init__()\n","  self.hidden_cell_dim=hidden_cell_dim\n","  self.inp_dim=inp_dim\n","  self.out_dim=out_dim\n","  self.lstm=nn.LSTM(self.inp_dim,self.hidden_cell_dim,num_layers=2,batch_first=True)\n","  self.linear=nn.Linear(self.hidden_cell_dim,self.out_dim)\n","  self.log_softmax=nn.LogSoftmax(dim=1)\n","  self.c0=c0\n","  self.h0=h0\n"," def forward(self,batch_data):\n","  rnn_out,_=self.lstm(batch_data,(self.h0,self.c0))\n","  out=rnn_out[:,-1,:].view(batch_data.shape[0],-1)\n","  scores=self.log_softmax(self.linear(out))\n","  return scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_hMFr9yCCA_","colab_type":"code","outputId":"332606c4-fe27-4265-e8ee-9fc6cdb70622","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["use_cuda = not False and torch.cuda.is_available()\n","print(use_cuda)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["True\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eu1ag2WsCt8B","colab_type":"code","colab":{}},"source":["h0 = torch.randn(2,64,128).cuda(device)\n","c0= torch.randn(2,64,128).cuda(device)\n","model =ManytooneLstm(128,39,10,c0,h0).cuda(device)\n","loss_fun=nn.NLLLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n","data_set_train=RawDataset(\"feats_labels_new_train.h5\",64)\n","data_set_dev=RawDataset(\"feats_labels_new_dev.h5\",64)\n","data_set_test=RawDataset(\"feats_labels_new_test.h5\",64)\n","train_loader = data_utils.DataLoader(data_set_train,batch_size=1,shuffle=True)\n","dev_loader = data_utils.DataLoader(data_set_dev,batch_size=1,shuffle=False)\n","test_loader = data_utils.DataLoader(data_set_test,batch_size=1,shuffle=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dW6hLGaC1ki","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"raViapFEC6O5","colab_type":"code","outputId":"b6b39c03-da07-47f9-9270-b1fd9ca58854","colab":{"base_uri":"https://localhost:8080/","height":598}},"source":["count=0\n","for epoch in range(0,30):\n"," tot_loss=0\n"," dev_loss=0\n"," for d in train_loader:\n","  data_batch=[]\n","  labels_batch=[]\n","  for label in range(0,len(d)):\n","   data_batch.append(d[label][:,:,:-1].view(-1,39))\n","   labels_batch.append(d[label][:,0,-1][0])\n"," #print(data_batch[0])\n","  batch_data_tensor=torch.tensor(pad_sequence(data_batch).transpose(0,1).clone().detach(),dtype=torch.float32)\n","  batch_labels_tensor=torch.tensor(labels_batch,dtype=torch.long)\n","  predictions=model(batch_data_tensor.cuda(device))\n","  loss=loss_fun(predictions,batch_labels_tensor.cuda(device))\n","  tot_loss=tot_loss+loss.item()\n","  optimizer.zero_grad()\n","  loss.backward()testing_online\n","  optimizer.step()\n","  count=count+1\n"," for d in dev_loader:\n","  data_batch=[]\n","  labels_batch=[]\n","  for label in range(0,len(d)):\n","   data_batch.append(d[label][:,:,:-1].view(-1,39))\n","   labels_batch.append(d[label][:,0,-1][0])\n","  batch_data_tensor=torch.tensor(pad_sequence(data_batch).transpose(0,1).clone().detach(),dtype=torch.float32)\n","  batch_labels_tensor=torch.tensor(labels_batch,dtype=torch.long)\n","  predictions=model(batch_data_tensor.cuda(device))\n","  loss=loss_fun(predictions,batch_labels_tensor.cuda(device))\n","  dev_loss=dev_loss+loss.item()\n"," print(\"epoch:\",epoch,\"train_loss:\",tot_loss,\"dev_loss\",dev_loss)\n"," if epoch % 10 == 0:\n","  torch.save(model.state_dict(),\"model\"+str(epoch)+\".pt\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 0 train_loss: 622.1106490492821 dev_loss 65.9388701915741\n","epoch: 1 train_loss: 224.92398220300674 dev_loss 30.132918141782284\n","epoch: 2 train_loss: 121.02582162246108 dev_loss 22.264910973608494\n","epoch: 3 train_loss: 81.46238598227501 dev_loss 16.510986488312483\n","epoch: 4 train_loss: 62.282275553792715 dev_loss 17.239564817398787\n","epoch: 5 train_loss: 50.59651064872742 dev_loss 13.213451493531466\n","epoch: 6 train_loss: 40.2070733550936 dev_loss 14.329188887029886\n","epoch: 7 train_loss: 34.87017427012324 dev_loss 10.945388250052929\n","epoch: 8 train_loss: 29.959842586889863 dev_loss 11.909979276359081\n","epoch: 9 train_loss: 28.75616285018623 dev_loss 11.9822404012084\n","epoch: 10 train_loss: 24.579663449898362 dev_loss 11.936259508132935\n","epoch: 11 train_loss: 23.586732091382146 dev_loss 11.727192714810371\n","epoch: 12 train_loss: 19.508164515718818 dev_loss 12.340268567204475\n","epoch: 13 train_loss: 22.432873932644725 dev_loss 14.096912488341331\n","epoch: 14 train_loss: 17.290733851492405 dev_loss 11.785844326019287\n","epoch: 15 train_loss: 16.696025133132935 dev_loss 12.012000419199467\n","epoch: 16 train_loss: 15.116915183141828 dev_loss 10.53450831770897\n","epoch: 17 train_loss: 14.106009379029274 dev_loss 9.408130940049887\n","epoch: 18 train_loss: 16.354813039302826 dev_loss 10.48067408055067\n","epoch: 19 train_loss: 11.528983442112803 dev_loss 11.113662030547857\n","epoch: 20 train_loss: 11.902080638334155 dev_loss 11.992278344929218\n","epoch: 21 train_loss: 14.596172623336315 dev_loss 12.928923897445202\n","epoch: 22 train_loss: 8.941498355939984 dev_loss 14.093242086470127\n","epoch: 23 train_loss: 9.263012394309044 dev_loss 11.723420683294535\n","epoch: 24 train_loss: 11.278834331780672 dev_loss 11.60294401831925\n","epoch: 25 train_loss: 8.091864006593823 dev_loss 13.004022784531116\n","epoch: 26 train_loss: 8.482344163581729 dev_loss 13.271550804376602\n","epoch: 27 train_loss: 6.004099762067199 dev_loss 14.606736097484827\n","epoch: 28 train_loss: 7.207377610728145 dev_loss 13.566644798964262\n","epoch: 29 train_loss: 7.1996644120663404 dev_loss 12.700758047401905\n"],"name":"stdout"}]}]}