{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"maskrcnn_custom_tf_colab.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["[View in Colaboratory](https://colab.research.google.com/github/RomRoc/maskrcnn_train_tensorflow_colab/blob/master/maskrcnn_custom_tf_colab.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"nGiIgx6PQR_i","colab_type":"text"},"source":["#Mask R-CNN instance segmentation with custom dataset in Google Colab\n","Jupyter notebook providing steps to train a **Matterport Mask R-CNN** model with custom dataset.\n","\n","It runs in [Google Colab](https://colab.research.google.com/) using [Matterport framework](https://github.com/matterport/Mask_RCNN) with TensorFlow backend.\n","\n","**Requirements are only dataset images and annotations file.**\n","\n","**Colab Runtime type: Python3, GPU enabled.**"]},{"cell_type":"markdown","metadata":{"id":"umEL6-vlmXmj","colab_type":"text"},"source":["#Making Dataset\n","I generated dataset annotations with [VGG Image Annotator](http://www.robots.ox.ac.uk/~vgg/software/via/).\n","\n","Notebook train a model for one class object detection. It is possible to slightly modify notebook to train model for multiple classes.\n","\n","Before running notebook, we need to create dataset:\n","\n","\n","1.   Collect various pictures of objects to detect\n","3.   Create annotation files in VGG\n","4.   Create image.zip file having structure defined below\n","5.   Upload the zip file in your Google Drive\n","\n","Zip file structure:\n","```\n","images.zip\n","|- \"train\" directory\n","  |- jpg image files of training data\n","  |- \"via_region_data.json\" annotations file of training data\n","|- \"val\" directory\n","  |- jpg image files of validation data\n","  |- \"via_region_data.json\" annotations file of validation data\n","```\n","Check my image.zip file as dataset example."]},{"cell_type":"markdown","metadata":{"id":"ywU9FM5qn6Wx","colab_type":"text"},"source":["#Install required packages"]},{"cell_type":"code","metadata":{"id":"39Wtm53bG7xW","colab_type":"code","outputId":"6b7ea6ba-7476-429c-f6e2-e153b3954953","executionInfo":{"status":"ok","timestamp":1560767654875,"user_tz":-330,"elapsed":9289,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}},"colab":{"base_uri":"https://localhost:8080/","height":40}},"source":["%cd\n","  \n","!git clone --quiet https://github.com/matterport/Mask_RCNN.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/root\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GZY2h5buS9xb","colab_type":"code","outputId":"9b61d201-ebc2-478a-b90f-dfa08d6a82b1","executionInfo":{"status":"ok","timestamp":1560767678488,"user_tz":-330,"elapsed":12546,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}},"colab":{"base_uri":"https://localhost:8080/","height":3274}},"source":["%cd ~/Mask_RCNN\n","\n","!pip install -q PyDrive\n","!pip install -r requirements.txt\n","!python setup.py install"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/root/Mask_RCNN\n","\u001b[K     |████████████████████████████████| 993kB 2.8MB/s \n","\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.16.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (4.3.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.29.10)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.0.3)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.15.0)\n","Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.14.0rc1)\n","Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.2.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.4.5.20)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.8.0)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.2.9)\n","Requirement already satisfied: IPython[all] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->-r requirements.txt (line 3)) (0.46)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.5.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.3)\n","Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.0.3)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.8)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.33.4)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.7.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.1.7)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.13.1)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.14.0rc0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.11.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.8.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.7.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.6.4.post2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.1.3)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.7.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.16)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (41.0.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n","Collecting ipyparallel; extra == \"all\" (from IPython[all]->-r requirements.txt (line 12))\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/82/aaa7a357845a98d4028f27c799f0d3bb2fe55fc1247c73dc712b4ae2344c/ipyparallel-6.2.4-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.21.0)\n","Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.5.1)\n","Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.5.0)\n","Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.5)\n","Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.4.2)\n","Requirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.0)\n","Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.6.1)\n","Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.4.2)\n","Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.2.2)\n","Requirement already satisfied: nose>=0.10.1; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.3.7)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.15.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.1.1)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.1.7)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (17.0.0)\n","Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.5.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.2.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2019.3.9)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.4.0)\n","Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.1.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.2)\n","Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.14)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (19.0)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.7.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.0)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.1)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n","Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.4.2)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.2)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.1)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n","Installing collected packages: ipyparallel\n","Successfully installed ipyparallel-6.2.4\n","WARNING:root:Fail load requirements file, so using default ones.\n","running install\n","running bdist_egg\n","running egg_info\n","creating mask_rcnn.egg-info\n","writing mask_rcnn.egg-info/PKG-INFO\n","writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n","writing top-level names to mask_rcnn.egg-info/top_level.txt\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","reading manifest template 'MANIFEST.in'\n","writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/mrcnn\n","copying mrcnn/parallel_model.py -> build/lib/mrcnn\n","copying mrcnn/__init__.py -> build/lib/mrcnn\n","copying mrcnn/visualize.py -> build/lib/mrcnn\n","copying mrcnn/model.py -> build/lib/mrcnn\n","copying mrcnn/config.py -> build/lib/mrcnn\n","copying mrcnn/utils.py -> build/lib/mrcnn\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n","copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating dist\n","creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mask_rcnn-2.1-py3.6.egg\n","Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding mask-rcnn 2.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n","Processing dependencies for mask-rcnn==2.1\n","Finished processing dependencies for mask-rcnn==2.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6zZg68_koGU7","colab_type":"text"},"source":["#Download and extract dataset\n","Update fileId variable with Google Drive id of your image.zip dataset\n"]},{"cell_type":"code","metadata":{"id":"p3KxhAII1PDT","colab_type":"code","outputId":"2f58c669-dfce-4c0f-f2b0-4796f618fd27","executionInfo":{"status":"ok","timestamp":1560767732164,"user_tz":-330,"elapsed":26601,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}},"colab":{"base_uri":"https://localhost:8080/","height":62}},"source":["%cd ~/Mask_RCNN\n","#https://drive.google.com/open?id=1f_NHV-ZzGsZu5Xpz4tCusgrb-hbK4uPG\n","fileId = '1f_NHV-ZzGsZu5Xpz4tCusgrb-hbK4uPG'\n","\n","import os\n","from zipfile import ZipFile\n","from shutil import copy\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","os.makedirs('dataset')\n","os.chdir('dataset')\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fileName = fileId + '.zip'\n","downloaded = drive.CreateFile({'id': fileId})\n","downloaded.GetContentFile(fileName)\n","ds = ZipFile(fileName)\n","ds.extractall()\n","os.remove(fileName)\n","print('Extracted zip file ' + fileName)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/root/Mask_RCNN\n","Extracted zip file 1f_NHV-ZzGsZu5Xpz4tCusgrb-hbK4uPG.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Hjjc40apLpd","colab_type":"text"},"source":["#Edit settings file\n","*  find and replace occurrences of \"balloon\" and \"Balloon\" with name of your object\n","*  set epochs number\n"]},{"cell_type":"code","metadata":{"id":"0SVHFnl5Hwe3","colab_type":"code","outputId":"c2ee91c5-37bd-49a5-e6ce-50c89319bc6e","executionInfo":{"status":"ok","timestamp":1560767745135,"user_tz":-330,"elapsed":8681,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}},"colab":{"base_uri":"https://localhost:8080/","height":40}},"source":["%cd ~/Mask_RCNN\n","\n","!cp ~/Mask_RCNN/samples/balloon/balloon.py ./dog.py\n","\n","!sed -i -- 's/balloon/dog/g' dog.py\n","!sed -i -- 's/Balloon/Dog/g' dog.py\n","!sed -i -- 's/epochs=30/epochs=5/g' dog.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/root/Mask_RCNN\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AjmxrVOwq0rC","colab_type":"text"},"source":["#Train model\n","Pretrained weights options are COCO, ImageNet or a model trained before"]},{"cell_type":"code","metadata":{"id":"EJGrimv2Xuf3","colab_type":"code","outputId":"8729916c-cbc7-4bc4-edef-ac93416d2991","colab":{"base_uri":"https://localhost:8080/","height":3844},"executionInfo":{"status":"ok","timestamp":1560768606490,"user_tz":-330,"elapsed":852355,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}}},"source":["%cd ~/Mask_RCNN\n","\n","!python dog.py train --dataset=dataset/ --weights=coco"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/root/Mask_RCNN\n","Using TensorFlow backend.\n","Weights:  coco\n","Dataset:  dataset/\n","Logs:  /logs\n","\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     2\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.9\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 2\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                14\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           dog\n","NUM_CLASSES                    2\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                100\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n","WARNING: Logging before flag parsing goes to stderr.\n","W0617 10:35:58.370397 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0617 10:35:58.412356 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0617 10:35:58.433925 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0617 10:35:58.465708 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0617 10:35:58.467625 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","W0617 10:36:00.962538 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0617 10:36:01.843216 140406238730112 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0617 10:36:01.973527 140406238730112 deprecation_wrapper.py:119] From /root/Mask_RCNN/mrcnn/model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","W0617 10:36:02.038318 140406238730112 deprecation_wrapper.py:119] From /root/Mask_RCNN/mrcnn/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0617 10:36:02.060155 140406238730112 deprecation.py:506] From /root/Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","Downloading pretrained model to /mask_rcnn_coco.h5 ...\n","... done downloading pretrained model!\n","Loading weights  /mask_rcnn_coco.h5\n","2019-06-17 10:36:07.379329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-06-17 10:36:07.381735: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x199d0840 executing computations on platform Host. Devices:\n","2019-06-17 10:36:07.381779: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n","2019-06-17 10:36:07.387974: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n","2019-06-17 10:36:07.651653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:07.652213: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x199d0bc0 executing computations on platform CUDA. Devices:\n","2019-06-17 10:36:07.652241: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2019-06-17 10:36:07.652535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:07.652890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2019-06-17 10:36:07.667314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-06-17 10:36:07.837741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-06-17 10:36:07.915026: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n","2019-06-17 10:36:07.935796: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n","2019-06-17 10:36:08.125691: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n","2019-06-17 10:36:08.235726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n","2019-06-17 10:36:08.609928: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","2019-06-17 10:36:08.610239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:08.610812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:08.611173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n","2019-06-17 10:36:08.614318: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n","2019-06-17 10:36:08.616564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-06-17 10:36:08.616598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n","2019-06-17 10:36:08.616612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n","2019-06-17 10:36:08.618470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:08.618980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-06-17 10:36:08.619347: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-06-17 10:36:08.619403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","Training network heads\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /logs/dog20190617T1036/mask_rcnn_dog_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","W0617 10:36:16.785218 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n","W0617 10:36:21.536337 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","W0617 10:36:21.536717 140406238730112 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/5\n","2019-06-17 10:36:58.897138: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n","2019-06-17 10:37:02.261498: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n","2019-06-17 10:37:04.311745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n","100/100 [==============================] - 212s 2s/step - loss: 0.5912 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0547 - mrcnn_class_loss: 0.0198 - mrcnn_bbox_loss: 0.3190 - mrcnn_mask_loss: 0.1963 - val_loss: 0.3701 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.1187 - val_mrcnn_class_loss: 0.0057 - val_mrcnn_bbox_loss: 0.1117 - val_mrcnn_mask_loss: 0.1329\n","Epoch 2/5\n","100/100 [==============================] - 139s 1s/step - loss: 0.2022 - rpn_class_loss: 0.0012 - rpn_bbox_loss: 0.0340 - mrcnn_class_loss: 0.0026 - mrcnn_bbox_loss: 0.0671 - mrcnn_mask_loss: 0.0973 - val_loss: 0.3234 - val_rpn_class_loss: 0.0014 - val_rpn_bbox_loss: 0.1140 - val_mrcnn_class_loss: 0.0030 - val_mrcnn_bbox_loss: 0.0892 - val_mrcnn_mask_loss: 0.1157\n","Epoch 3/5\n","100/100 [==============================] - 140s 1s/step - loss: 0.1702 - rpn_class_loss: 6.8838e-04 - rpn_bbox_loss: 0.0239 - mrcnn_class_loss: 0.0026 - mrcnn_bbox_loss: 0.0517 - mrcnn_mask_loss: 0.0914 - val_loss: 0.3151 - val_rpn_class_loss: 0.0011 - val_rpn_bbox_loss: 0.1480 - val_mrcnn_class_loss: 0.0021 - val_mrcnn_bbox_loss: 0.0477 - val_mrcnn_mask_loss: 0.1162\n","Epoch 4/5\n","100/100 [==============================] - 139s 1s/step - loss: 0.1458 - rpn_class_loss: 6.5062e-04 - rpn_bbox_loss: 0.0241 - mrcnn_class_loss: 0.0026 - mrcnn_bbox_loss: 0.0322 - mrcnn_mask_loss: 0.0863 - val_loss: 0.3221 - val_rpn_class_loss: 8.0517e-04 - val_rpn_bbox_loss: 0.1345 - val_mrcnn_class_loss: 0.0026 - val_mrcnn_bbox_loss: 0.0654 - val_mrcnn_mask_loss: 0.1189\n","Epoch 5/5\n","100/100 [==============================] - 139s 1s/step - loss: 0.1274 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0182 - mrcnn_class_loss: 0.0025 - mrcnn_bbox_loss: 0.0234 - mrcnn_mask_loss: 0.0821 - val_loss: 0.2426 - val_rpn_class_loss: 9.2101e-04 - val_rpn_bbox_loss: 0.0960 - val_mrcnn_class_loss: 0.0018 - val_mrcnn_bbox_loss: 0.0339 - val_mrcnn_mask_loss: 0.1099\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"laqF3Tihrqs3","colab_type":"text"},"source":["#Run inference on test dataset"]},{"cell_type":"code","metadata":{"id":"2o7dH-mRX2A0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1930},"outputId":"833d8499-171d-4abc-8612-49cc15cc67b6","executionInfo":{"status":"ok","timestamp":1560768678737,"user_tz":-330,"elapsed":13714,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}}},"source":["import os\n","import cv2\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import skimage\n","import glob\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","\n","import dog\n","\n","# Root directory of the project\n","ROOT_DIR = os.getcwd()\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","\n","custom_WEIGHTS_PATH = sorted(glob.glob(\"/logs/*/mask_rcnn_*.h5\"))[-1]\n","\n","%matplotlib inline \n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","config = dog.DogConfig()\n","custom_DIR = os.path.join(ROOT_DIR, \"dataset\")\n","\n","class InferenceConfig(config.__class__):\n","    # Run detection on one image at a time\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","config = InferenceConfig()\n","config.display()\n","\n","# Device to load the neural network on.\n","# Useful if you're training a model on the same \n","# machine, in which case use CPU and leave the\n","# GPU for training.\n","DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n","\n","# Inspect the model in training or inference modes\n","# values: 'inference' or 'training'\n","# TODO: code for 'training' test mode not ready yet\n","TEST_MODE = \"inference\"\n","\n","def get_ax(rows=1, cols=1, size=16):\n","    \"\"\"Return a Matplotlib Axes array to be used in\n","    all visualizations in the notebook. Provide a\n","    central point to control graph sizes.\n","    \n","    Adjust the size attribute to control how big to render images\n","    \"\"\"\n","    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n","    return ax\n","  \n","# Load validation dataset\n","dataset = dog.DogDataset()\n","dataset.load_dog(custom_DIR, \"val\")\n","\n","# Must call before using the dataset\n","dataset.prepare()\n","\n","print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n","\n","# Create model in inference mode\n","with tf.device(DEVICE):\n","    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n","                              config=config)\n","\n","# load the last model you trained\n","# weights_path = model.find_last()[1]\n","\n","# Load weights\n","print(\"Loading weights \", custom_WEIGHTS_PATH)\n","model.load_weights(custom_WEIGHTS_PATH, by_name=True)\n","\n","from importlib import reload # was constantly changin the visualization, so I decided to reload it instead of notebook\n","reload(visualize)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0617 10:51:08.098198 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0617 10:51:08.104563 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0617 10:51:08.108799 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0617 10:51:08.133774 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0617 10:51:08.137216 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     1\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.9\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      1\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 1\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                14\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           dog\n","NUM_CLASSES                    2\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                100\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","\n","\n","Images: 5\n","Classes: ['BG', 'dog']\n"],"name":"stdout"},{"output_type":"stream","text":["W0617 10:51:10.828800 139779069233024 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","W0617 10:51:11.268350 139779069233024 deprecation_wrapper.py:119] From /root/Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0617 10:51:11.279825 139779069233024 deprecation.py:323] From /root/Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0617 10:51:11.287266 139779069233024 deprecation.py:506] From /root/Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","W0617 10:51:11.547945 139779069233024 deprecation_wrapper.py:119] From /root/Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","W0617 10:51:11.556090 139779069233024 deprecation_wrapper.py:119] From /root/Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","W0617 10:51:11.843991 139779069233024 deprecation.py:323] From /root/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading weights  /logs/dog20190617T1036/mask_rcnn_dog_0005.h5\n","Re-starting from epoch 5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<module 'mrcnn.visualize' from '/root/Mask_RCNN/mrcnn/visualize.py'>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"X7iSzccTL9hM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":5598,"output_embedded_package_id":"15VJZDPuc8olNcI37RdL2YFPGMYRB_3hY"},"outputId":"2be627d8-004d-48a5-a4d9-a200d971d1b1","executionInfo":{"status":"ok","timestamp":1560768719297,"user_tz":-330,"elapsed":21568,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}}},"source":["#image_id = random.choice(dataset.image_ids)\n","for image_id in dataset.image_ids:\n","  image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","      modellib.load_image_gt(dataset, config, image_id, use_mini_mask=False)\n","  info = dataset.image_info[image_id]\n","  print(\"image ID: {}.{} ({}) {}\".format(info[\"source\"], info[\"id\"], image_id, \n","                                         dataset.image_reference(image_id)))\n","\n","  \n","  # Run object detection\n","  results = model.detect([image], verbose=1)\n","\n","  # Display results\n","  ax = get_ax(1)\n","  r = results[0]\n","  visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n","                              dataset.class_names, r['scores'], ax=ax,\n","                              title=\"Predictions\")\n","  log(\"gt_class_id\", gt_class_id)\n","  log(\"gt_bbox\", gt_bbox)\n","  log(\"gt_mask\", gt_mask)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"rfJLeoFSGHQ3","colab_type":"code","colab":{}},"source":["!pip install -U -q PyDrive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jJyL4L5GNMw","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTwnujSpGf9u","colab_type":"code","colab":{}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive= GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXR8PZ-YGufl","colab_type":"code","colab":{}},"source":["#https://drive.google.com/open?id=10OWVM9HAohV7xS9jSB1yVxS-uYbrGdGY\n","f = drive.CreateFile({'id':'10OWVM9HAohV7xS9jSB1yVxS-uYbrGdGY'})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pgagEDlkHCKT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":634},"outputId":"8e27b4cb-6772-4162-aa1f-8126840db229","executionInfo":{"status":"ok","timestamp":1560769493887,"user_tz":-330,"elapsed":1249,"user":{"displayName":"K Naveen Kumar","photoUrl":"https://lh3.googleusercontent.com/--I87pF_AlyQ/AAAAAAAAAAI/AAAAAAAAABY/56cMEeCAw74/s64/photo.jpg","userId":"04223549038337132700"}}},"source":["f.GetContentFile('dog.jpeg')"],"execution_count":13,"outputs":[{"output_type":"stream","text":["W0617 11:04:52.817052 139779069233024 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n","    from google.appengine.api import memcache\n","ModuleNotFoundError: No module named 'google.appengine'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n","    from oauth2client.contrib.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n","    from oauth2client.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n","    from . import file_cache\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n","    'file_cache is unavailable when using oauth2client >= 4.0.0')\n","ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DCOgBEw9HHYv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}