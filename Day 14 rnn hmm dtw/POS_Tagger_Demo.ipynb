{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"POS_Tagger_Demo.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"UaYWZhI3_Btq","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","from urllib.request import urlopen\n","\n","from IPython.core.display import HTML\n","from itertools import chain\n","from collections import Counter, defaultdict, namedtuple, OrderedDict\n","from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_m2NNGsBuHa","colab_type":"code","colab":{}},"source":["Sentence = namedtuple(\"Sentence\", \"words tags\")\n","data_URL = 'https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/brown-universal.txt'  \n","tags_URL = 'https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/tags-universal.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"reeP1uJYFi-K","colab_type":"code","colab":{}},"source":["def read_data(url):\n","    \"\"\"Read tagged sentence data\"\"\"\n","    with urlopen(url) as f:\n","        sentence_lines = [l.split(\"\\n\") for l in f.read().decode(\"utf-8\").split(\"\\n\\n\")]    \n","    return OrderedDict(((s[0], Sentence(*zip(*[l.strip().split(\"\\t\")\n","                        for l in s[1:]]))) for s in sentence_lines if s[0]))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LsidViGmFrKh","colab_type":"code","colab":{}},"source":["def read_tags(url):\n","    \"\"\"Read a list of word tag classes\"\"\"\n","    with urlopen(url) as f:\n","        tags = f.read().decode(\"utf-8\").split(\"\\n\")   \n","    return frozenset(tags)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfQolOc4GJgZ","colab_type":"code","colab":{}},"source":["class Subset(namedtuple(\"BaseSet\", \"sentences keys vocab X tagset Y N stream\")):\n","    def __new__(cls, sentences, keys):\n","        word_sequences = tuple([sentences[k].words for k in keys])\n","        tag_sequences = tuple([sentences[k].tags for k in keys])\n","        wordset = frozenset(chain(*word_sequences))\n","        tagset = frozenset(chain(*tag_sequences))\n","        N = sum(1 for _ in chain(*(sentences[k].words for k in keys)))\n","        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n","        return super().__new__(cls, {k: sentences[k] for k in keys}, keys, wordset, word_sequences,\n","                               tagset, tag_sequences, N, stream.__iter__)\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __iter__(self):\n","        return iter(self.sentences.items())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UILe45GVBcbH","colab_type":"code","colab":{}},"source":["class Dataset(namedtuple(\"_Dataset\", \"sentences keys vocab X tagset Y training_set testing_set N stream\")):\n","    def __new__(cls, tag_url, data_url, train_test_split=0.8, seed=112890):\n","        tagset = read_tags(tag_url)\n","        #pdb.set_trace()\n","        sentences = read_data(data_url)\n","        keys = tuple(sentences.keys())\n","        wordset = frozenset(chain(*[s.words for s in sentences.values()]))\n","        word_sequences = tuple([sentences[k].words for k in keys])\n","        tag_sequences = tuple([sentences[k].tags for k in keys])\n","        N = sum(1 for _ in chain(*(s.words for s in sentences.values())))\n","        \n","        # split data into train/test sets\n","        _keys = list(keys)\n","        if seed is not None: random.seed(seed)\n","        random.shuffle(_keys)\n","        split = int(train_test_split * len(_keys))\n","        training_data = Subset(sentences, _keys[:split])\n","        testing_data = Subset(sentences, _keys[split:])\n","        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n","        return super().__new__(cls, dict(sentences), keys, wordset, word_sequences, tagset,\n","                               tag_sequences, training_data, testing_data, N, stream.__iter__)\n","\n","    def __len__(self):\n","        \n","        return len(self.sentences)\n","\n","    def __iter__(self):\n","        return iter(self.sentences.items())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzdrsB-DilNe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"59335d13-2f40-4ccf-c4f6-040fcfd305d9","executionInfo":{"status":"ok","timestamp":1558092841423,"user_tz":-330,"elapsed":4593,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["data = Dataset(tags_URL, data_URL, train_test_split=0.8)\n","\n","print(\"There are {} sentences in the corpus.\".format(len(data)))\n","print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n","print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n","\n","assert len(data) == len(data.training_set) + len(data.testing_set), \\\n","       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""],"execution_count":123,"outputs":[{"output_type":"stream","text":["There are 57340 sentences in the corpus.\n","There are 45872 sentences in the training set.\n","There are 11468 sentences in the testing set.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJhtuFJj_82Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"bff6b330-3834-4d9f-f30e-a453aa4701c6","executionInfo":{"status":"ok","timestamp":1558092843324,"user_tz":-330,"elapsed":809,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["key = 'b100-38532'\n","print(len(data.sentences))\n","print(\"Sentence: {}\".format(key))\n","print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n","print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"],"execution_count":124,"outputs":[{"output_type":"stream","text":["57340\n","Sentence: b100-38532\n","words:\n","\t('Perhaps', 'it', 'was', 'right', ';', ';')\n","tags:\n","\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5YY9QFqgixUv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"c63dff49-d1af-4e0a-9151-918e22dc14f9","executionInfo":{"status":"ok","timestamp":1558092394307,"user_tz":-330,"elapsed":875,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["print(\"There are a total of {} samples of {} unique words in the corpus.\"\n","      .format(data.N, len(data.vocab)))\n","print(\"There are {} samples of {} unique words in the training set.\"\n","      .format(data.training_set.N, len(data.training_set.vocab)))\n","print(\"There are {} samples of {} unique words in the testing set.\"\n","      .format(data.testing_set.N, len(data.testing_set.vocab)))\n","print(\"There are {} words in the test set that are missing in the training set.\"\n","      .format(len(data.testing_set.vocab - data.training_set.vocab)))"],"execution_count":110,"outputs":[{"output_type":"stream","text":["There are a total of 1161192 samples of 56057 unique words in the corpus.\n","There are 928458 samples of 50536 unique words in the training set.\n","There are 232734 samples of 25112 unique words in the testing set.\n","There are 5521 words in the test set that are missing in the training set.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixnIk5Nlkzn5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":180},"outputId":"b74723cc-d0f9-4226-ef65-435b8c30ec5a","executionInfo":{"status":"ok","timestamp":1558092947922,"user_tz":-330,"elapsed":896,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["for i in range(2):    \n","    print(\"Sentence {}:\".format(i + 1), data.X[i])\n","    print()\n","    print(\"Labels {}:\".format(i + 1), data.Y[i])\n","    print()"],"execution_count":125,"outputs":[{"output_type":"stream","text":["Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n","\n","Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n","\n","Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n","\n","Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5a9Z7K7QlLlG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":160},"outputId":"3b631a5e-9b47-4246-b023-92f1e9597e0c","executionInfo":{"status":"ok","timestamp":1558093024151,"user_tz":-330,"elapsed":929,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["print(\"\\nStream (word, tag) pairs:\\n\")\n","for i, pair in enumerate(data.stream()):\n","    print(\"\\t\", pair)\n","    if i > 3: break"],"execution_count":126,"outputs":[{"output_type":"stream","text":["\n","Stream (word, tag) pairs:\n","\n","\t ('Mr.', 'NOUN')\n","\t ('Podger', 'NOUN')\n","\t ('had', 'VERB')\n","\t ('thanked', 'VERB')\n","\t ('him', 'PRON')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"br5pLyMdlRqO","colab_type":"code","colab":{}},"source":["def pair_counts(tags, words):\n","    d = defaultdict(lambda: defaultdict(int))\n","    for tag, word in zip(tags, words):\n","        d[tag][word] += 1\n","        \n","    return d\n","tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n","words = [word for i, (word, tag) in enumerate(data.training_set.stream())]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0Lppy7Flh-h","colab_type":"code","colab":{}},"source":["FakeState = namedtuple('FakeState', 'name')\n","\n","class MFCTagger:\n","    missing = FakeState(name = '<MISSING>')\n","    \n","    def __init__(self, table):\n","        self.table = defaultdict(lambda: MFCTagger.missing)\n","        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n","        \n","    def viterbi(self, seq):\n","        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n","        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n","    \n","tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n","words = [word for i, (word, tag) in enumerate(data.training_set.stream())]\n","\n","word_counts = pair_counts(words, tags)\n","mfc_table = dict((word, max(tags.keys(), key=lambda key: tags[key])) for word, tags in word_counts.items())\n","\n","mfc_model = MFCTagger(mfc_table)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cl314155lnW5","colab_type":"code","colab":{}},"source":["def replace_unknown(sequence):\n","    \n","    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n","\n","def simplify_decoding(X, model):\n","    \n","    _, state_path = model.viterbi(replace_unknown(X))\n","    return [state[1].name for state in state_path[1:-1]]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHqguITVofOI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":430},"outputId":"4636c6be-ce0c-4907-e01f-c1e200adead9","executionInfo":{"status":"ok","timestamp":1558093892270,"user_tz":-330,"elapsed":1053,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["for key in data.testing_set.keys[:2]:\n","    print(\"Sentence Key: {}\\n\".format(key))\n","    print(\"Predicted labels:\\n-----------------\")\n","    print(simplify_decoding(data.sentences[key].words, mfc_model))\n","    print()\n","    print(\"Actual labels:\\n--------------\")\n","    print(data.sentences[key].tags)\n","    print(\"\\n\")"],"execution_count":132,"outputs":[{"output_type":"stream","text":["Sentence Key: b100-28144\n","\n","Predicted labels:\n","-----------------\n","['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n","\n","Actual labels:\n","--------------\n","('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n","\n","\n","Sentence Key: b100-23146\n","\n","Predicted labels:\n","-----------------\n","['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n","\n","Actual labels:\n","--------------\n","('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kiFMMxjoor8s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"9416f084-6551-432b-d3a6-88821322588f","executionInfo":{"status":"ok","timestamp":1558093962314,"user_tz":-330,"elapsed":1855,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["def accuracy(X, Y, model):\n","    \n","    correct = total_predictions = 0\n","    for observations, actual_tags in zip(X, Y):\n","        \n","        # The model.viterbi call in simplify_decoding will return None if the HMM\n","        # raises an error (for example, if a test sentence contains a word that\n","        # is out of vocabulary for the training set). Any exception counts the\n","        # full sentence as an error (which makes this a conservative estimate).\n","        try:\n","            most_likely_tags = simplify_decoding(observations, model)\n","            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n","        except:\n","            pass\n","        total_predictions += len(observations)\n","    return correct / total_predictions\n","\n","#Evaluate the accuracy of the MFC tagger.\n","\n","mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n","print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n","\n","mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n","print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))"],"execution_count":134,"outputs":[{"output_type":"stream","text":["training accuracy mfc_model: 95.72%\n","testing accuracy mfc_model: 93.01%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RpHpJullo-TK","colab_type":"text"},"source":["**Build a Hidden Markov Model (HMM) Tagger** "]},{"cell_type":"code","metadata":{"id":"XVFsMil5o6SX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"108a9872-1c6a-4355-ba0d-d181b3058c41","executionInfo":{"status":"ok","timestamp":1558094210627,"user_tz":-330,"elapsed":756,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["def unigram_counts(sequences):\n","\n","    return Counter(sequences)\n","\n","tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n","tag_unigrams = unigram_counts(tags)\n","\n","print(tag_unigrams)\n","print(sum(list(tag_unigrams.values())))"],"execution_count":143,"outputs":[{"output_type":"stream","text":["Counter({'NOUN': 220632, 'VERB': 146161, '.': 117757, 'ADP': 115808, 'DET': 109671, 'ADJ': 66754, 'ADV': 44877, 'PRON': 39383, 'CONJ': 30537, 'PRT': 23906, 'NUM': 11878, 'X': 1094})\n","928458\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4THhrtcTp4-i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"faee4841-6876-4cc1-dfbd-9924e35e5a4e","executionInfo":{"status":"ok","timestamp":1558094332486,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["def bigram_counts(sequences):\n","\n","    d = Counter(sequences)\n","    return d\n","\n","tags = [tag for i, (word, tag) in enumerate(data.stream())]\n","o = [(tags[i],tags[i+1]) for i in range(0,len(tags)-2,2)]\n","tag_bigrams = bigram_counts(o)\n","\n","print(tag_bigrams)\n","print(sum(list(tag_bigrams.values())))"],"execution_count":145,"outputs":[{"output_type":"stream","text":["Counter({('DET', 'NOUN'): 42818, ('NOUN', '.'): 39180, ('NOUN', 'ADP'): 33955, ('ADP', 'DET'): 33105, ('ADJ', 'NOUN'): 27380, ('NOUN', 'VERB'): 21839, ('NOUN', 'NOUN'): 20633, ('ADP', 'NOUN'): 18458, ('PRON', 'VERB'): 17362, ('VERB', 'VERB'): 16877, ('DET', 'ADJ'): 16357, ('VERB', 'ADP'): 15460, ('VERB', 'DET'): 15046, ('.', 'DET'): 10913, ('.', '.'): 10396, ('.', 'NOUN'): 10104, ('VERB', 'ADV'): 9431, ('PRT', 'VERB'): 9304, ('VERB', 'NOUN'): 8869, ('.', 'ADP'): 8232, ('NOUN', 'CONJ'): 8198, ('.', 'PRON'): 7945, ('VERB', '.'): 7405, ('.', 'VERB'): 6822, ('ADV', 'VERB'): 6791, ('.', 'CONJ'): 6477, ('ADP', 'ADJ'): 6014, ('VERB', 'PRT'): 6001, ('.', 'ADV'): 5810, ('VERB', 'ADJ'): 5291, ('ADP', 'PRON'): 5018, ('VERB', 'PRON'): 5015, ('ADV', '.'): 4752, ('CONJ', 'NOUN'): 4682, ('DET', 'VERB'): 4368, ('ADJ', '.'): 4212, ('ADV', 'ADP'): 3987, ('ADV', 'ADJ'): 3780, ('CONJ', 'VERB'): 3728, ('NOUN', 'ADV'): 3717, ('ADJ', 'ADP'): 3676, ('.', 'ADJ'): 3097, ('ADP', 'VERB'): 3016, ('CONJ', 'DET'): 2900, ('NUM', 'NOUN'): 2870, ('NOUN', 'PRON'): 2840, ('ADV', 'ADV'): 2666, ('PRON', '.'): 2548, ('NOUN', 'PRT'): 2545, ('ADJ', 'ADJ'): 2394, ('.', 'PRT'): 2391, ('NOUN', 'DET'): 2243, ('CONJ', 'ADJ'): 2157, ('ADP', 'NUM'): 2130, ('ADV', 'DET'): 2068, ('NUM', '.'): 2066, ('NOUN', 'ADJ'): 1796, ('CONJ', 'ADV'): 1759, ('ADJ', 'CONJ'): 1548, ('ADP', 'ADP'): 1435, ('CONJ', 'ADP'): 1395, ('ADV', 'PRON'): 1392, ('PRON', 'ADP'): 1387, ('PRT', 'ADP'): 1357, ('PRON', 'ADV'): 1335, ('.', 'NUM'): 1332, ('VERB', 'CONJ'): 1329, ('CONJ', 'PRON'): 1290, ('PRT', 'DET'): 1273, ('DET', 'ADV'): 1214, ('ADP', 'ADV'): 1174, ('PRT', '.'): 1166, ('NOUN', 'NUM'): 1099, ('NUM', 'ADP'): 997, ('ADP', 'PRT'): 993, ('ADV', 'NOUN'): 894, ('DET', '.'): 885, ('VERB', 'NUM'): 813, ('ADV', 'PRT'): 785, ('ADJ', 'PRT'): 758, ('ADJ', 'VERB'): 718, ('ADP', '.'): 707, ('DET', 'PRON'): 679, ('DET', 'NUM'): 659, ('DET', 'ADP'): 630, ('PRON', 'PRT'): 592, ('PRT', 'ADV'): 541, ('ADV', 'CONJ'): 506, ('PRT', 'NOUN'): 501, ('CONJ', 'PRT'): 468, ('ADJ', 'ADV'): 443, ('PRON', 'DET'): 437, ('NUM', 'ADJ'): 433, ('CONJ', '.'): 416, ('DET', 'DET'): 392, ('ADV', 'NUM'): 365, ('X', 'X'): 348, ('CONJ', 'NUM'): 340, ('NUM', 'VERB'): 336, ('NUM', 'CONJ'): 303, ('ADJ', 'NUM'): 298, ('PRT', 'ADJ'): 292, ('PRON', 'CONJ'): 275, ('ADJ', 'DET'): 249, ('PRON', 'ADJ'): 243, ('PRON', 'NOUN'): 220, ('X', '.'): 205, ('PRON', 'PRON'): 200, ('PRT', 'CONJ'): 172, ('NUM', 'NUM'): 168, ('PRT', 'PRT'): 160, ('ADJ', 'PRON'): 159, ('NUM', 'ADV'): 155, ('ADP', 'CONJ'): 134, ('DET', 'PRT'): 130, ('NUM', 'DET'): 123, ('.', 'X'): 107, ('PRT', 'PRON'): 105, ('DET', 'X'): 90, ('PRT', 'NUM'): 83, ('NUM', 'PRON'): 61, ('NOUN', 'X'): 47, ('NUM', 'PRT'): 46, ('DET', 'CONJ'): 44, ('ADP', 'X'): 38, ('X', 'VERB'): 37, ('X', 'NOUN'): 37, ('X', 'ADP'): 33, ('ADJ', 'X'): 30, ('PRON', 'NUM'): 25, ('X', 'CONJ'): 15, ('VERB', 'X'): 15, ('CONJ', 'X'): 7, ('X', 'PRON'): 5, ('X', 'ADV'): 5, ('X', 'PRT'): 5, ('X', 'DET'): 4, ('CONJ', 'CONJ'): 4, ('ADV', 'X'): 3, ('X', 'ADJ'): 2, ('NUM', 'X'): 2, ('X', 'NUM'): 1, ('PRON', 'X'): 1, ('PRT', 'X'): 1})\n","580595\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A1w7MoT_qryR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"06426e5e-26fb-4ba2-d5d6-6ea9f2d01199","executionInfo":{"status":"ok","timestamp":1558094506657,"user_tz":-330,"elapsed":856,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["def starting_counts(sequences):\n","    \n","    d = Counter(sequences)\n","    return d\n","\n","tags = [tag for i, (word, tag) in enumerate(data.stream())]\n","starts_tag = [i[0] for i in data.Y]\n","tag_starts = starting_counts(starts_tag)\n","\n","print(tag_starts)\n","print(sum(list(tag_starts.values())))"],"execution_count":146,"outputs":[{"output_type":"stream","text":["Counter({'DET': 12238, 'PRON': 9157, 'NOUN': 8093, 'ADP': 7044, 'ADV': 5238, '.': 5099, 'CONJ': 2817, 'VERB': 2588, 'PRT': 2103, 'ADJ': 1969, 'NUM': 964, 'X': 30})\n","57340\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wCp1gPbjq-NM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"6d9de45f-3871-467d-e1ee-00b15970a3e3","executionInfo":{"status":"ok","timestamp":1558094561291,"user_tz":-330,"elapsed":830,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["def ending_counts(sequences):\n","    \n","    d = Counter(sequences)\n","    return d\n","\n","end_tag = [i[len(i)-1] for i in data.Y]\n","tag_ends = ending_counts(end_tag)\n","\n","print(tag_ends)\n","print(sum(list(tag_ends.values())))"],"execution_count":147,"outputs":[{"output_type":"stream","text":["Counter({'.': 56149, 'NOUN': 914, 'VERB': 102, 'NUM': 80, 'ADJ': 31, 'ADV': 20, 'DET': 18, 'PRT': 9, 'ADP': 8, 'PRON': 5, 'CONJ': 2, 'X': 2})\n","57340\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MBNjptlWqnKb","colab_type":"code","colab":{}},"source":["basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n","\n","tags = [tag for i, (word, tag) in enumerate(data.stream())]\n","words = [word for i, (word, tag) in enumerate(data.stream())]\n","\n","tags_count=unigram_counts(tags)\n","tag_words_count=pair_counts(tags,words)\n","\n","starting_tag_list=[i[0] for i in data.Y]\n","ending_tag_list=[i[-1] for i in data.Y]\n","\n","starting_tag_count=starting_counts(starting_tag_list)#the number of times a tag occured at the start\n","ending_tag_count=ending_counts(ending_tag_list)      #the number of times a tag occured at the end\n","\n","to_pass_states = []\n","for tag, words_dict in tag_words_count.items():\n","    total = float(sum(words_dict.values()))\n","    distribution = {word: count/total for word, count in words_dict.items()}\n","    tag_emissions = DiscreteDistribution(distribution)\n","    tag_state = State(tag_emissions, name=tag)\n","    to_pass_states.append(tag_state)\n","\n","basic_model.add_states()\n","\n","start_prob={}\n","\n","for tag in tags:\n","    start_prob[tag]=starting_tag_count[tag]/tags_count[tag]\n","\n","for tag_state in to_pass_states :\n","    basic_model.add_transition(basic_model.start,tag_state,start_prob[tag_state.name])\n","\n","end_prob={}\n","\n","for tag in tags:\n","    end_prob[tag]=ending_tag_count[tag]/tags_count[tag]\n","for tag_state in to_pass_states :\n","    basic_model.add_transition(tag_state,basic_model.end,end_prob[tag_state.name])\n","\n","transition_prob_pair={}\n","\n","for key in tag_bigrams.keys():\n","    transition_prob_pair[key]=tag_bigrams.get(key)/tags_count[key[0]]\n","for tag_state in to_pass_states :\n","    for next_tag_state in to_pass_states :\n","        basic_model.add_transition(tag_state,next_tag_state,transition_prob_pair[(tag_state.name,next_tag_state.name)])\n","\n","basic_model.bake()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KtVXaE3RrSrW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":430},"outputId":"11e3bfb5-721b-4e96-e422-9a091d5951e0","executionInfo":{"status":"ok","timestamp":1558094626349,"user_tz":-330,"elapsed":828,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["for key in data.testing_set.keys[:2]:\n","    print(\"Sentence Key: {}\\n\".format(key))\n","    print(\"Predicted labels:\\n-----------------\")\n","    print(simplify_decoding(data.sentences[key].words, basic_model))\n","    print()\n","    print(\"Actual labels:\\n--------------\")\n","    print(data.sentences[key].tags)\n","    print(\"\\n\")"],"execution_count":149,"outputs":[{"output_type":"stream","text":["Sentence Key: b100-28144\n","\n","Predicted labels:\n","-----------------\n","['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n","\n","Actual labels:\n","--------------\n","('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n","\n","\n","Sentence Key: b100-23146\n","\n","Predicted labels:\n","-----------------\n","['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n","\n","Actual labels:\n","--------------\n","('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z4SBrA7Irejs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"41c194e1-cc56-4050-b172-d863e8a560da","executionInfo":{"status":"ok","timestamp":1558094677634,"user_tz":-330,"elapsed":2633,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n","print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n","\n","hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n","print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))"],"execution_count":150,"outputs":[{"output_type":"stream","text":["training accuracy basic hmm model: 97.49%\n","testing accuracy basic hmm model: 96.09%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xusgN-TvtHWT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"2e959c01-6f72-4faa-b7e3-a2fc1cf0efc0","executionInfo":{"status":"ok","timestamp":1558096041543,"user_tz":-330,"elapsed":737,"user":{"displayName":"Dinesh Jain","photoUrl":"","userId":"08961783981389029404"}}},"source":["#print(data.testing_set.keys[1])\n","#print(data.sentences[data.testing_set.keys[1]].words)\n","#print(data.sentences[data.testing_set.keys[1]].tags)\n","\n","test_input = 'Tara speaks good english .'\n","#labels = 'NOUN VERB NOUN ADV .'\n","labels = 'NOUN \tVERB \tADJ NOUN .'\n","print(\"Predicted labels:\\n--------------\")\n","print(simplify_decoding(tuple(test_input.split()), basic_model))\n","print(\"Actual labels:\\n--------------\")\n","print(labels.split())\n","\n"],"execution_count":170,"outputs":[{"output_type":"stream","text":["Predicted labels:\n","--------------\n","['PRON', 'VERB', 'ADJ', 'NOUN', '.']\n","Actual labels:\n","--------------\n","['NOUN', 'VERB', 'ADJ', 'NOUN', '.']\n"],"name":"stdout"}]}]}