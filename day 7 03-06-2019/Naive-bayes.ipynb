{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer AI @ IIT_H.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jclkwLq85xfF",
        "colab_type": "text"
      },
      "source": [
        "This program requires you to implement a **Naive Bayes classifier** from the scratch and compare it with the builtin version of scikit-learn.\n",
        "\n",
        "For this problem, we assume that the likelihood of x is a **gaussian** and the prior is uniform=> p(c) is equal for all values of C. So we can infer from this information that \n",
        "p(x|c) â‰¡ $N(x;\\mu,\\sigma^2)$ for some $\\sigma^2$  and  $\\mu$.\n",
        "\n",
        "\n",
        "To simplify your understanding, the skeleton of the code is already provided, you would be required to only write the code to the following functions\n",
        "\n",
        "*  dataset_splitter\n",
        "*   mean_var_calc\n",
        "*   calc_log_posterior\n",
        "*   predict\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU40Hm_2eFqM",
        "colab_type": "text"
      },
      "source": [
        "**Import the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxdXnHV1eDwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nKYhLPLeYjc",
        "colab_type": "text"
      },
      "source": [
        "**Loading and splitting the dataset into train and testsets**\n",
        "\n",
        "Please fill in the below function which can be used to split the data in 80:20 ratio and return 4 numpy arrays- train_x,  train_y, test_x, test_y\n",
        "\n",
        "*   train_x: (0.8*len(iris.data),4), \n",
        "*   train_y : (0.8*len(iris.data),)\n",
        "*   test_x:(0.2*len(iris.data),4)\n",
        "*   test_y:(0.2*len(iris.data),)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "potkSmjEedRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "def dataset_splitter(iris):\n",
        "  \n",
        "  # space for code\n",
        "  \n",
        "  return (train_x,train_y,test_x,test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29nwz-fhsV9Y",
        "colab_type": "text"
      },
      "source": [
        "**Function to calculate suitable mean and variance for the best fitting gaussian for the training set**.\n",
        "\n",
        "This function calculates the mean and variance along all dimensions of the training set\n",
        " and returns are: \n",
        "\n",
        "*   mean : shape- (4,)\n",
        "*  variance : shape- (4,)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rywp-d8ahegq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "def mean_var_calculator(X):\n",
        "  \n",
        "  # space for code\n",
        "  \n",
        "  return (mean,var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWAiScgesb_M",
        "colab_type": "text"
      },
      "source": [
        "**Calculating log posterior**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arnjuE-OXhlG",
        "colab_type": "text"
      },
      "source": [
        "\\begin{equation}\n",
        "Posterior(dataset|\\sigma_c^{2},\\mu_c,class label=C)=P(C).\\Pi_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma_c^2}e^{\\frac{-(x_i-\\mu_c)^2}{2\\sigma_c^2}}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQHmqYhFh2_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this function takes 3 parameters as input- \n",
        "#1. data sample for which the posterior is to be calculated\n",
        "#2. Mean, Variance of the gaussian w.r.t which posterior is to be estimated\n",
        "#Assume a Uniform Prior on the class labels\n",
        "#return the log of posterior calculated- shape: X.shape[0]\n",
        "def calc_log_posterior(x,mean,var):\n",
        "  \n",
        "  # space for code\n",
        "  \n",
        "  return (posterior)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0CLzcByUVZq",
        "colab_type": "text"
      },
      "source": [
        "   **Making predictions using the model that we have**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybhBVS3aoGF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inputs: 1. x- datapoint to which the prediction is to be calculated\n",
        "#        2. set_0 - a tuple of mean and variance for training samples belonging to class:0\n",
        "#           set_1 - a tuple of mean and variance for training samples belonging to class:1\n",
        "#           set_2 - a tuple of mean and variance for training samples belonging to class:2   \n",
        "#        3. class_label: integer in range:{0,1,2,3}\n",
        "def predict(x, set_0,set_1,set_2):\n",
        "  \n",
        "  # space for code\n",
        "  \n",
        "  return (class_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sShBOt2BfC5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_x,train_y,test_x,test_y=dataset_splitter(iris)\n",
        "samples_0=[]\n",
        "samples_1=[]\n",
        "samples_2=[]\n",
        "for i,row in enumerate(train_x):\n",
        "  if train_y[i]==0:    \n",
        "    samples_0.append(list(row))\n",
        "  elif train_y[i]==1:\n",
        "    samples_1.append(list(row))\n",
        "  elif train_y[i]==2:\n",
        "    samples_2.append(list(row))\n",
        "samples_0 = (np.array(samples_0),np.array([0]*len(samples_0)))  #data with only samples from class:0\n",
        "samples_1 = (np.array(samples_1),np.array([1]*len(samples_1))) #data with only samples from class:1\n",
        "samples_2 = (np.array(samples_2),np.array([2]*len(samples_2))) #data with only samples from class:2\n",
        "\n",
        "set_0,set_1,set_2 = mean_var_calculator(samples_0[0]),mean_var_calculator(samples_1[0]),mean_var_calculator(samples_2[0])\n",
        "y_pred=[]\n",
        "\n",
        "for i,row in enumerate(test_x):\n",
        "  y_pred.append(predict(row,set_0,set_1,set_2))\n",
        "y_pred=np.array(y_pred)\n",
        "print ('accuracy of the model is {}'.format((y_pred==test_y).mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8RrMTaAN2tL",
        "colab_type": "text"
      },
      "source": [
        "**Comparison with builtin model**\n",
        "\n",
        "Test how the builtin classifier performs on the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBYrIqppYMWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gnb = GaussianNB()\n",
        "# your code comes here\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4uDvk4EZpWG",
        "colab_type": "text"
      },
      "source": [
        "**Steps:** \n",
        "  1. fit the model on the train_x\n",
        "  2. Make predictions using inbuilt functions and print the accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo35kxHLBHcI",
        "colab_type": "text"
      },
      "source": [
        "**Hints:**\n",
        "\\begin{equation}\n",
        "p(c|x)=p(c).\\Pi_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma_c^2}e^{\\frac{-(x_i-\\mu_c)^2}{2\\sigma_c^2}}\n",
        "\\end{equation}\n",
        "Since we would require the best gaussian to fit our training data, we maximize the log posterior experssion w.r.t  $\\mu$ and $\\sigma^2$ \n",
        "\n",
        "$\\max_{\\mu, \\sigma^2} log [p(c|x)]$\n",
        "\n",
        "=>$\\frac{\\partial log [p(c|x)]}{\\partial \\mu}=0$ and $\\frac{\\partial log [p(c|x)]}{\\partial \\sigma^2}=0$ \n",
        "\n",
        "=> $\\mu = \\frac {\\sum_i^n (x_i) } {n}$\n",
        "\n",
        "=> $\\sigma^2 = \\frac {\\sum_i^n (x_i-\\mu)^2 } {n}$"
      ]
    }
  ]
}